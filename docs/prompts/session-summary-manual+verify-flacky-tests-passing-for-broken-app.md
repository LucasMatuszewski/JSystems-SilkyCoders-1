> Prompt generated by Claude Code when I asked it to clarify and organize my thoughts and add all required details to let me start a new session (to avoid automatic session compression and loss of context in summarization = manual control of context)

---

What Was Implemented (Previous Sessions)

Backend (Java/Spring Boot):

- PolicyService — loads 3 Sinsay policy docs, routes by intent (return/complaint)
- SinsayTools — @Tool showReturnForm(type) that triggers form display
- AGUIAgentExecutor — fully replaced demo tools, added buildSystemPrompt(), detectIntent(), multimodal photo handling in buildGraphInput(), extractFormSubmission(), FormSubmissionData
  record
- AGUISSEController — added .onErrorResume() error handling, emits RUN_ERROR with Polish user-friendly messages (Ollama down, auth, timeout, generic)
- SessionService, PhotoStorageService — R2DBC/H2 in-memory persistence
- Domain entities + repositories: Session, FormSubmission, ChatMessage
- Schema: schema.sql with 3 tables

Frontend (Next.js/CopilotKit):

- SinsayChat.tsx — main chat with useCopilotAction("showReturnForm") and renderAndWaitForResponse
- ReturnForm.tsx — all PRD fields, Zod validation, base64 photo via Canvas resize
- VerdictMessage.tsx — green/red verdict rendering with pattern detection
- imageResize.ts — Canvas API resize to max 1024px
- schemas.ts — Zod form schema with Polish errors
- Sinsay branding in globals.css, layout.tsx, page.tsx

Tests: 59 backend tests pass, 32 frontend tests pass, 5 Playwright E2E tests (unreliable — see bugs)

---

Known Bugs & Issues

Bug 1 — Image processing fails
When user submits the return form with a photo, the backend fails. Error appears in FE saying "issue with API, may need to provide key." Exact error unknown — base64 strings flood the logs
making it unreadable. The multimodal handling in AGUIAgentExecutor.buildGraphInput() uses Spring AI's UserMessage.builder().media(mimeType, resource). Unknown if Ollama's API endpoint and
the Spring AI Ollama client are being used correctly for multimodal/vision requests.

Bug 2 — Logging is broken for debugging
Base64 image strings (potentially MBs) are logged to console. This makes logs unreadable. No structured logging, no log-to-file. When something fails (e.g., Ollama returns an error for a
vision request), we don't see the actual error response from Ollama/the model — only that something failed.

Bug 3 — Tests give false confidence (critical)
All 59 backend tests and 5 E2E Playwright tests were passing when the app was completely broken:

- Unit tests mock everything — never hit real paths
- Bean tests only check instanceof — never invoke LLM
- AGUISSEControllerTests mocks AGUIAgent — never exercises real agent logic
- Playwright E2E: explicitly filters out all network/connection errors; "send message" test passes whether or not message was sent (input cleared || message appeared)
- No test ever submits a form with a photo and verifies the verdict flow end-to-end
- No test catches the image processing failure the user just experienced

Bug 4 — Ollama fallback to OpenAI not working (noted, not fixed)
resolveModel() has a fallback chain, but when Ollama returns errors (503, model unavailable), the error propagates as a Flux error rather than triggering the fallback. The fallback only
applies at startup model selection, not at runtime when Ollama is alive but the specific model/request fails.

Bug 5 — E2E Playwright selectors are fragile
Current Playwright tests select by CSS classes and DOM structure. Refactoring UI components will break tests even if functionality is unchanged.

---

Relevant File Locations

src/main/java/org/bsc/langgraph4j/agui/
├── AGUIAgentExecutor.java # buildGraphInput() — multimodal handling (photo bug here)
├── AGUISSEController.java # error handling (recently fixed)
└── AGUIEvent.java # RunErrorEvent, etc.

src/main/java/com/silkycoders1/jsystemssilkycodders1/
├── service/PolicyService.java
├── service/SessionService.java
├── service/PhotoStorageService.java
├── tools/SinsayTools.java
└── JSystemsSilkyCodders1Application.java # bean factory

src/main/resources/application.properties # model config, R2DBC URL
src/main/resources/schema.sql

frontend/src/app/component/
├── ReturnForm.tsx # photo upload + base64 encoding
├── SinsayChat.tsx # useCopilotAction for showReturnForm
└── VerdictMessage.tsx

frontend/src/app/lib/
├── imageResize.ts # Canvas resize
└── schemas.ts # Zod validation

.claude/agents/ # specialist agent instructions
src/CLAUDE.md # backend agent instructions
frontend/CLAUDE.md # frontend agent instructions
docs/PRD-Sinsay-PoC.md
docs/ADR-Sinsay-PoC.md

---

Prompt for New Session

# Task: Fix Image Processing, Logging, and Test Quality

## Context

This is a Sinsay PoC — a Spring Boot (WebFlux) + LangGraph4j + Spring AI backend
with a Next.js 16 + CopilotKit frontend. The app lets users describe a return/complaint
in chat, submit a form with product details and a photo, and receive an AI verdict.

The full implementation is complete but has critical bugs described below.

Read `docs/PRD-Sinsay-PoC.md`, `docs/ADR-Sinsay-PoC.md`, `src/CLAUDE.md`,
and `frontend/CLAUDE.md` before starting any work.

---

## Problem 1 (Priority 1): Fix Logging — Structured, Trimmed, File-Capable

### What's wrong

- Base64-encoded photo strings (potentially MBs) are being logged to the console,
  making logs completely unreadable when debugging.
- When Ollama or any model provider returns an error for a request (especially
  multimodal/vision requests), we don't see the actual error body — only that
  the Flux failed.
- No log-to-file capability. All logs go to stdout only.

### What to fix

1. **Configure Logback** (already included in Spring Boot — no new dependency needed)
   to write structured logs to a rolling file (`logs/app.log`) with daily rotation
   and 7-day retention. Use `src/main/resources/logback-spring.xml`. Keep console
   output for local dev.

2. **Trim sensitive/large data from log statements.** Specifically:
   - Any log that includes photo/image data MUST truncate base64 strings to first
     50 characters + `...[N bytes]`. Example:
     `"photo": "data:image/jpeg;base64,/9j/4AAQ...[45231 bytes]"`
   - Audit all `log.info()`, `log.warn()`, `log.error()` calls in
     `AGUIAgentExecutor.java` — trim any object that may contain base64.

3. **Log Ollama/model responses on error.** In `AGUISSEController.mapErrorToUserMessage()`
   and in the `onErrorResume()` handler, log the FULL throwable message and cause
   at ERROR level BEFORE mapping to user-friendly text. This is the key debugging data.

4. **Add request/response logging for outbound model calls.** Check if Spring AI or
   LangGraph4j provides a way to log the actual HTTP request/response to Ollama.
   Use `logging.level.org.springframework.ai=DEBUG` in `application.properties`
   for dev. Document this in `src/CLAUDE.md`.

TDD requirement: Write a test that verifies base64 strings are NOT present in log
output when processing a form submission with a photo.

---

## Problem 2 (Priority 2): Fix Image Processing for Ollama Multimodal

### What's wrong

When the user submits the return form with a photo, the backend fails with an error
visible in the frontend ("issue with API, may need to provide key").

The multimodal handling is in `AGUIAgentExecutor.buildGraphInput()`. It uses
Spring AI's `UserMessage.builder().media(mimeType, resource)` to attach the photo.
The exact error from Ollama is currently invisible (see Problem 1).

### Research needed first

1. Check the Spring AI documentation (use Context7 MCP) for the correct way to
   send multimodal/vision requests to an Ollama model. The API surface for
   `OllamaChatModel` multimodal may differ from OpenAI's.
   Key question: Does `UserMessage.builder().media()` work the same for both
   Ollama and OpenAI in Spring AI 1.0.0? Or is there a different API?

2. Check which Ollama models support vision. In `application.properties`,
   the configured model is `OLLAMA_KIMI_K2_5_CLOUD`. Verify this model supports
   vision/multimodal. If not, identify which locally-pulled model does
   (e.g., `llava`, `moondream`, `qwen2.5-vl`).

3. In `AGUIAgentExecutor.buildGraphInput()`, the photo arrives as a base64 string
   in `FormSubmissionData.photo()`. Verify the base64 is being correctly decoded
   and wrapped as a `ByteArrayResource` with the right MIME type.

### Fix approach

- After fixing logging (Problem 1), reproduce the error and read the actual
  Ollama error response from logs.
- Fix the `UserMessage.builder()` multimodal construction based on what Spring AI
  actually requires for Ollama.
- If the current model doesn't support vision, update the configuration or add
  a model-capability check that gracefully falls back to text-only analysis.

TDD requirement: Write an integration test that submits a `FormSubmissionData`
with a real (small) JPEG base64 image and verifies the executor builds a valid
`UserMessage` with media content. Test should fail currently, pass after fix.

---

## Problem 3 (Priority 3): Fix Tests to Catch Real Failures

### Why tests are useless right now

All 59 backend tests and all 5 Playwright E2E tests pass even when the app is
completely broken. Specifically:

- `AGUISSEControllerTests` mocks `AGUIAgent` entirely — the real agent logic
  (model calls, multimodal, LangGraph4j graph) is never exercised.
- `AGUIAgentBeanConfigTests` only checks `instanceof` — never invokes LLM.
- Playwright tests explicitly filter out ALL network/connection errors and use
  `input.value === '' || messages.count > 0` — passes even when backend is down.
- No test submits a form with a photo and verifies a verdict comes back.
- No test verifies that the SSE stream actually produces `TEXT_MESSAGE_*` events.

### What good tests look like for this app

**Backend integration tests (with real Spring context, mocked at the HTTP boundary):**

- Use `@SpringBootTest(webEnvironment = RANDOM_PORT)` + `WebTestClient`
- Mock the `ChatModel` (NOT the `AGUIAgent`) so LangGraph4j graph runs for real
- Test the full SSE event sequence: `RUN_STARTED → TEXT_MESSAGE_START →
TEXT_MESSAGE_CONTENT → TEXT_MESSAGE_END → RUN_FINISHED`
- Test that submitting a `RunAgentInput` with a `ResultMessage` containing form
  JSON produces a multimodal AI message (even if model is mocked)
- Test that `showReturnForm` tool call is emitted when intent is detected
- Tests MUST fail if the SSE stream emits a `RUN_ERROR` event

**Frontend E2E (Playwright):**

- Add `data-testid` attributes to all key elements in:
  `SinsayChat.tsx`, `ReturnForm.tsx`, `VerdictMessage.tsx`
  Example: `data-testid="chat-input"`, `data-testid="return-form"`,
  `data-testid="form-submit-btn"`, `data-testid="verdict-approved"`, etc.
- Playwright tests MUST use `getByTestId()` or `getByLabel()` or `getByRole()`,
  NEVER by CSS class or DOM structure.
- The "no errors" test MUST NOT filter out backend connection errors. If the
  backend is down, the test MUST FAIL.
- Add a test that sends a message containing "zwrot" and verifies the return
  form appears (data-testid="return-form" is visible).
- Add a test that fills the return form with a test image and submits it,
  then verifies a verdict message appears (data-testid="verdict-approved" or
  data-testid="verdict-rejected").
- These tests require both backend and Ollama to be running. Document this in
  `frontend/CLAUDE.md`.

---

## Problem 4 (Priority 4): Update Agent Instructions and CLAUDE.md Files

### What to do

Reorganize the testing guidelines to prevent future agents from writing
useless tests that give false confidence.

1. **Create `src/test/CLAUDE.md`** (backend test guidelines):
   - Tests MUST test real behavior, not mocked implementations
   - Mock only at the HTTP/network boundary (ChatModel HTTP calls), not the
     business logic layer
   - Every new feature needs a test that would FAIL if the feature is broken
   - Forbidden: mocking AGUIAgent in tests that claim to test the SSE controller
   - Forbidden: tests that pass when the AI model returns a 503
   - Required: integration tests that verify the full SSE event sequence
   - Required: tests for multimodal flow (photo submission → verdict)
   - Move detailed test commands from `src/CLAUDE.md` to this file

2. **Create `frontend/test/CLAUDE.md`** (frontend test guidelines):
   - Vitest + RTL: test component behavior from user perspective, not implementation
   - Playwright: ALWAYS use `data-testid`, `getByRole()`, or `getByLabel()`
   - NEVER select by CSS class (`.copilotkit-chat`) or DOM structure (`div > span`)
   - Playwright tests require backend running — document setup in README-style header
   - E2E tests MUST fail if backend is down (do NOT filter network errors)
   - Move detailed test commands from `frontend/CLAUDE.md` to this file

3. **Update `.claude/agents/sinsay-spring-backend` agent instructions**:
   Add explicit rules:
   - "NEVER write tests that mock the component under test"
   - "Tests must exercise the full call stack from HTTP request to SSE response"
   - "A test suite that passes when the app is broken provides NEGATIVE value"
   - "Consult `src/test/CLAUDE.md` for test patterns"

4. **Update `.claude/agents/sinsay-frontend-dev` agent instructions**:
   Add explicit rules:
   - "ALWAYS add `data-testid` to interactive/observable elements"
   - "Playwright tests MUST fail if backend is unreachable"
   - "Consult `frontend/test/CLAUDE.md` for test patterns"

5. **Update `src/CLAUDE.md` and `frontend/CLAUDE.md`**:
   - Remove detailed test commands and patterns (moved to test CLAUDE.md files)
   - Add one-liner: "See `src/test/CLAUDE.md` / `frontend/test/CLAUDE.md` for
     test standards and commands"
   - Keep: TDD process, test-first requirement, completion criteria

---

## Also Note (Do Not Fix Now)

**Ollama runtime fallback is broken:** The model fallback chain in
`AGUIAgentExecutor.resolveModel()` runs at startup only. If Ollama is running
but returns an error for a specific request (e.g., model not found, vision
request rejected), the error propagates as a Flux error rather than trying
the next model. The `OPENAI_API_KEY` env var is set and was working before —
the fallback logic needs to be moved to runtime error recovery, not just startup
resolution. Track this as a separate bug for a future session.

---

## Order of Operations

1. Fix logging first (Problem 1) — you need visibility to diagnose Problem 2
2. Read the actual error from logs, then fix image processing (Problem 2)
3. Write failing tests that reproduce Problem 2 BEFORE fixing it (TDD)
4. Fix Problem 2 until tests pass
5. Update CLAUDE.md and agent instructions (Problem 4)
6. Update Playwright tests with data-testid attributes (Problem 3)
7. Write meaningful integration tests for the full SSE + multimodal flow (Problem 3)

## Completion Criteria

The task is complete when:

- [ ] Logs are clean (no base64 flooding), errors from Ollama are visible
- [ ] Log file is written to `logs/app.log` with rolling config
- [ ] Form submission with a photo produces a verdict (not an error)
- [ ] A test exists that submits a form with a photo and FAILS if verdict is not produced
- [ ] A Playwright test exists that submits the return form and verifies verdict appears
- [ ] Playwright tests use `data-testid` exclusively for selection
- [ ] Playwright tests FAIL when backend is down (no error filtering)
- [ ] `src/test/CLAUDE.md` and `frontend/test/CLAUDE.md` exist with quality standards
- [ ] Agent instructions in `.claude/agents/` updated with test quality rules
- [ ] All existing tests still pass (no regressions)
